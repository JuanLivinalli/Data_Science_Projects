{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPMG Skill Assesment - Juan Livinalli\n",
    "## Named Entity Recognition on the MIT Movie Corpus\n",
    "In this notebook I will develop the code to train a model to be able to perform NER on the MIT Movie Corpus and on new sentences. For this NLP task I will use the neural network library Keras to design and train a neural network to perform NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "First, I download the engtest test and engtrain dataset from the MIT Movie Corpus and save them in the 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      " 77  246k   77  192k    0     0  61982      0  0:00:04  0:00:03  0:00:01 61962\n",
      "100  246k  100  246k    0     0  79595      0  0:00:03  0:00:03 --:--:-- 79570\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0  989k    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      " 22  989k   22  224k    0     0  79313      0  0:00:12  0:00:02  0:00:10 79313\n",
      " 54  989k   54  544k    0     0   120k      0  0:00:08  0:00:04  0:00:04  120k\n",
      " 54  989k   54  544k    0     0   106k      0  0:00:09  0:00:05  0:00:04  106k\n",
      " 92  989k   92  912k    0     0   154k      0  0:00:06  0:00:05  0:00:01  204k\n",
      "100  989k  100  989k    0     0   164k      0  0:00:06  0:00:06 --:--:--  252k\n"
     ]
    }
   ],
   "source": [
    "!curl https://groups.csail.mit.edu/sls/downloads/movie/engtest.bio -o data/test.txt\n",
    "!curl https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio -o data/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will define a function to transform the BIO format into a list of sentences and a list of tags. I will the use this function to create the X predictor variables and the Y tags to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    file = open(file, 'r')\n",
    "    data_x, data_y = [], []\n",
    "    sentence, labels = [], []\n",
    "    for i in file:\n",
    "        line = i.strip(\"\\n\").split(\"\\t\")\n",
    "       \n",
    "        #len > 1 are words\n",
    "        if len(line) > 1:\n",
    "            sentence.append(line[1])\n",
    "            labels.append(line[0][2:]) if len(line[0]) > 1 else labels.append(line[0])\n",
    "       \n",
    "        #len == 1 are sentence breaks\n",
    "        if len(line) == 1:\n",
    "            data_x.append(' '.join(sentence))\n",
    "            data_y.append(labels)\n",
    "            sentence, labels = [], []\n",
    "    return data_x, data_y\n",
    "\n",
    "train_x, train_y = load_data(\"data/train.txt\")\n",
    "test_x, test_y = load_data(\"data/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Now, lets a look at the data in x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what movies star bruce willis',\n",
       " 'show me films with drew barrymore from the 1980s',\n",
       " 'what movies starred both al pacino and robert deniro',\n",
       " 'find me all of the movies that starred harold ramis and bill murray',\n",
       " 'find me a movie with a quote about baseball in it',\n",
       " 'what movies have mississippi in the title',\n",
       " 'show me science fiction films directed by steven spielberg',\n",
       " 'do you have any thrillers directed by sofia coppola',\n",
       " 'what leonard cohen songs have been used in a movie',\n",
       " 'show me films elvis films set in hawaii']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O', 'O', 'O', 'ACTOR', 'ACTOR'],\n",
       " ['O', 'O', 'O', 'O', 'ACTOR', 'ACTOR', 'O', 'O', 'YEAR'],\n",
       " ['O', 'O', 'O', 'O', 'ACTOR', 'ACTOR', 'O', 'ACTOR', 'ACTOR'],\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'ACTOR',\n",
       "  'ACTOR',\n",
       "  'O',\n",
       "  'ACTOR',\n",
       "  'ACTOR'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'O', 'TITLE', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'GENRE', 'GENRE', 'GENRE', 'O', 'O', 'DIRECTOR', 'DIRECTOR'],\n",
       " ['O', 'O', 'O', 'O', 'GENRE', 'O', 'O', 'DIRECTOR', 'DIRECTOR'],\n",
       " ['O', 'SONG', 'SONG', 'SONG', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " ['O', 'O', 'O', 'ACTOR', 'O', 'PLOT', 'PLOT', 'PLOT']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how many sentences we have in the train and test data. I also want to see what's the longest sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "total amount of sentences: 9775\n",
      "Maximum sentence length: 258\n",
      "test data\n",
      "total amount of sentences: 2443\n",
      "Maximum sentence length: 175\n"
     ]
    }
   ],
   "source": [
    "def sentence_feat(data_x):\n",
    "    #total amount of sentences in the dataset\n",
    "    total_sent = len(data_x)\n",
    "    print('total amount of sentences:',total_sent)\n",
    "\n",
    "    #longest sentence length in the dataset\n",
    "    maxlen = max([len(s) for s in data_x])\n",
    "    print ('Maximum sentence length:', maxlen)\n",
    "\n",
    "print('train data')\n",
    "sentence_feat(train_x)\n",
    "print('test data')\n",
    "sentence_feat(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum sentence is quite long, I will plot a histogram of the sentences lenght to see what is the sentence size for the majority of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sentence_hist(data_x):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.hist([len(s) for s in data_x],bins = 50)\n",
    "    plt.xlabel(\"Length of Sentences\")\n",
    "    plt.show()\n",
    "    \n",
    "sentence_hist(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the average lenght of a sentence in the data is near 50 words. \n",
    "## Data Preprocessing\n",
    "In order to prepare the data so that it can be used by the model, I will perform the following tranformation:\n",
    "\n",
    "Tokenize the data: The model doesn't not understand words, therefore the input data needs to be transformed through a process called tokenization where a number will be assigned to each distinct word. Here I've place the limit to tokenize up to 10000 words and I've also allocated one number for all words not in the vocabulary OOV.\n",
    "\n",
    "Pad the data: for our recurrent neural network to work we need all inputs to have the same dimensions, therefore we will make all sentence size equal by padding small sentences and truncating big sentences. I've chosen 50 as the number of words for all input sentences since, as seen in the histogram, the majority of sentences in the data have around 50 words.\n",
    "\n",
    "Perform word embeddings: I will use Keras embedding layer to embed the one-hot encoded words in the input into embedded words. By performing word embeddings I can reduce the dimensionality of my input from 10000 vectors to 100 vectors in an embedded matrix which is very helpful at reducing the complexity of our model since it will not need as many parametes if the input uses 100 vectors per word. Also, by training this layer, the embedding will find relationships between words in the vocab which can be very helpful for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000  #total words being tokenized\n",
    "MAX_LEN = 50       #total length of sentence\n",
    "\n",
    "#fit tokenizer\n",
    "tokenizer = Tokenizer (num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#tokenize & pad train data\n",
    "train_x_idx = tokenizer.texts_to_sequences(train_x)\n",
    "train_x_idx = pad_sequences(train_x_idx, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "#tokenize & pad test data\n",
    "test_x_idx = tokenizer.texts_to_sequences(test_x)\n",
    "test_x_idx = pad_sequences(test_x_idx, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at the word index created by the tokenization of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'the': 2,\n",
       " 'a': 3,\n",
       " 'movie': 4,\n",
       " 'what': 5,\n",
       " 'in': 6,\n",
       " 'is': 7,\n",
       " 'movies': 8,\n",
       " 'that': 9,\n",
       " 'was': 10,\n",
       " 'rated': 11,\n",
       " 'of': 12,\n",
       " 'with': 13,\n",
       " 'film': 14,\n",
       " 'about': 15}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(word_index.items())[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at one of the tokenized and padded sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,   8,  55, 257, 354,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I transform the tags in Y to vectors as well. In this case I want to have 13 vectors per tag, each one representing one category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DIRECTOR': 0,\n",
       " 'RATINGS_AVERAGE': 1,\n",
       " 'RATING': 2,\n",
       " 'SONG': 3,\n",
       " 'TITLE': 4,\n",
       " 'PLOT': 5,\n",
       " 'CHARACTER': 6,\n",
       " 'YEAR': 7,\n",
       " 'GENRE': 8,\n",
       " 'REVIEW': 9,\n",
       " 'ACTOR': 10,\n",
       " 'TRAILER': 11,\n",
       " 'O': 12}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_dict(data):\n",
    "    data_flattened = [item for sublist in data for item in sublist]  \n",
    "    tags = list(set(data_flattened))    #list of tags\n",
    "    tag_idx={}\n",
    "    for x,tag in enumerate(tags):\n",
    "        tag_idx[tag]=x                  #dict of tags\n",
    "    return tag_idx, len(tag_idx), tags\n",
    "\n",
    "y_dict, dictTot, tags = tag_dict(train_y)\n",
    "\n",
    "y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_transform(tag_dict, data_y, max_len):\n",
    "    y = [[tag_dict[w] for w in s] for s in data_y]\n",
    "    y =pad_sequences(y, maxlen=max_len, padding='post', value = y_dict['O'])\n",
    "    y = [to_categorical(i, num_classes = dictTot) for i in  y]\n",
    "    return y\n",
    "\n",
    "train_y_idx = tag_transform(y_dict,train_y,MAX_LEN)\n",
    "test_y_idx = tag_transform(y_dict,test_y,MAX_LEN)\n",
    "\n",
    "train_y_idx[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and evaluation\n",
    "\n",
    "Now that the data is transformed into the correct format, I proceed to build the model. \n",
    "\n",
    "I will use a Bidirectional LSTM (Long Short Term Memory) model as these models tend to perform well on natural language tasks. When assessing a word, Bidirectional LSTM models are capabe of taking account previous words and later words in the sentence in order to provide context, this is one of the main advantages of this model as the nature of a word is often defined by it's context within a sentence.\n",
    "\n",
    "For this model I will also use a dropout layer and a recurrent dropout in order to regularize the model to ensure it generalizes well to unseen data.\n",
    "\n",
    "Finally, I've placed a dense layer right after the LSTM layer with 13 outputs (1 for each category) from which later I can pick the vector output with the highest probability as the predicted tag for the specific word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 100  #dimension of word embedding\n",
    "\n",
    "#####Model#####\n",
    "input_words = Input(shape = (MAX_LEN,))\n",
    "model = Embedding(input_dim = MAX_WORDS, output_dim = DIM, input_length = MAX_LEN)(input_words)\n",
    "model = Dropout(0.2)(model)\n",
    "model = Bidirectional(LSTM(units = 128,return_sequences = True, recurrent_dropout = 0.1))(model)\n",
    "out = TimeDistributed(Dense(dictTot, activation = 'softmax'))(model)\n",
    "model = Model(inputs=input_words, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will compile the model using an adam optimizer and use the categorical crossentropy loss function (as I'm trying to predict the different categories of tags). Finally, I will use accuracy as the performance metric to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 50, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 50, 256)           234496    \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 50, 13)            3341      \n",
      "=================================================================\n",
      "Total params: 1,237,837\n",
      "Trainable params: 1,237,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above,I can see the layers and total parameters of my model as well as the tensor shapes of each layer. I want to make sure that my X and Y have the same dimensions as the model input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9775, 50)\n",
      "(9775, 50, 13)\n"
     ]
    }
   ],
   "source": [
    "train_y_idx=np.array(train_y_idx)\n",
    "test_y_idx=np.array(test_y_idx)\n",
    "\n",
    "print(train_x_idx.shape)\n",
    "print(train_y_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the dimensions match with the model requirements, so I proceed to fit the model. I use an input batch size of 64, I will leave 20% of the data for validation, and will run 10 epochs on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 70s 573ms/step - loss: 0.4700 - accuracy: 0.9152 - val_loss: 0.3079 - val_accuracy: 0.9204\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 64s 519ms/step - loss: 0.2480 - accuracy: 0.9289 - val_loss: 0.1780 - val_accuracy: 0.9467\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 63s 514ms/step - loss: 0.1406 - accuracy: 0.9636 - val_loss: 0.0962 - val_accuracy: 0.9763\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 66s 533ms/step - loss: 0.0838 - accuracy: 0.9793 - val_loss: 0.0695 - val_accuracy: 0.9808\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.0611 - accuracy: 0.9841 - val_loss: 0.0613 - val_accuracy: 0.9829\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 72s 586ms/step - loss: 0.0502 - accuracy: 0.9864 - val_loss: 0.0601 - val_accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 72s 584ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.0535 - val_accuracy: 0.9846\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 73s 590ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 0.0517 - val_accuracy: 0.9848\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 89s 720ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.0575 - val_accuracy: 0.9839\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 86s 697ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0594 - val_accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x35889400>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_idx, train_y_idx, batch_size = 64, verbose = 1, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the model has performed very well on the training data, achieving 99.18% accuracy. Now, I will run the model on the test data to see how it performs and ensure it's not overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 63ms/step - loss: 0.0658 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06583928316831589, 0.9825214743614197]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x_idx, test_y_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs quite well on the test data, achieving 98,25% accuracy which means it's generalizing well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I've created a function that can be used to test the model with any new sentence the user would like to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_predict(text):\n",
    "    word_list = text.split(\" \")\n",
    "    \n",
    "    #tokenize and pad\n",
    "    x_idx=tokenizer.texts_to_sequences([text])\n",
    "    x_idx = pad_sequences(x_idx, maxlen=MAX_LEN, padding='post')\n",
    "                          \n",
    "    #predict tags                     \n",
    "    p = model.predict(np.array(x_idx))\n",
    "    p = np.argmax(p, axis = -1)\n",
    "                          \n",
    "    #present results                      \n",
    "    print(\"{:10}\\t{}\\n\".format(\"Word\", \"Prediction\"))\n",
    "    print(\"-\" * 25)\n",
    "    for (w, pred) in zip(range(len(word_list)), p[0][:(len(text))]):\n",
    "        print(\"{:10}\\t{}\".format(word_list[w], tags[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I try a new sentence to see how well my model categorizes each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word      \tPrediction\n",
      "\n",
      "-------------------------\n",
      "did       \tO\n",
      "brad      \tACTOR\n",
      "pitt      \tACTOR\n",
      "star      \tO\n",
      "in        \tO\n",
      "the       \tO\n",
      "action    \tGENRE\n",
      "movie     \tO\n",
      "fight     \tTITLE\n",
      "club?     \tTITLE\n"
     ]
    }
   ],
   "source": [
    "text_predict(\"did brad pitt star in the action movie fight club?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the model is predicting well that Brad Pitt is an actor, that 'action' is a movie gender, and that Fight Club is the title of the movie.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Improvements\n",
    "\n",
    "For next steps, different hyperparameter values can be tried to see if the performance of the model improves. The model could be trained for more epochs, we could see how in every epoch the model improved, in the final epochs the improvements were smaller, nevertheless training for more epochs will most likely result in a slight improvement of performance. Different dropout values could be tried to see if the model generalizes better to the test data. A different architecture could also be tried, as an example a Second LSTM layer could be place on top of the first one, an another dropout layer could be added, A Conditional Random field (CRF) layer could also be added after the second LSTM layer, Bi-LSTM to CRF models have shown to perform well on NER tasks. Finally, changing the input sentence length to accept more words in the sentences could potencially improve the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset: trivia10k13test.bio\n",
    "\n",
    "For entity extraction in the second dataset I will use the same process I used in the first section and reuse some of the earlier functions. The first model gave good results so I will build and train a similar model for this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  428k    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100  428k  100  428k    0     0   254k      0  0:00:01  0:00:01 --:--:--  254k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  5 1743k    5 98304    0     0  81715      0  0:00:21  0:00:01  0:00:20 81715\n",
      "100 1743k  100 1743k    0     0   815k      0  0:00:02  0:00:02 --:--:--  815k\n"
     ]
    }
   ],
   "source": [
    "!curl https://groups.csail.mit.edu/sls/downloads/movie/trivia10k13test.bio -o data/test2.txt\n",
    "!curl https://groups.csail.mit.edu/sls/downloads/movie/trivia10k13train.bio -o data/train2.txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_x, train2_y = load_data(\"data/train2.txt\")\n",
    "test2_x, test2_y = load_data(\"data/test2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['steve mcqueen provided a thrilling motorcycle chase in this greatest of all ww 2 prison escape movies',\n",
       " 'liza minnelli and joel gray won oscars for their roles in this 1972 movie that follows nightclub entertainers in berlin as the nazis come to power',\n",
       " 'what is that tom hanks and julia roberts movie about hanks who plays a down on his luck average guy who goes back to college and gets taught by roberts',\n",
       " 'what is the movie making fun of macgyver by re enacting scenes similar to his movies',\n",
       " 'i am thinking of an animated film based on a classic theodor geisel children s novel about a young boy s quest to save the trees']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "total amount of sentences: 7816\n",
      "Maximum sentence length: 396\n",
      "test data\n",
      "total amount of sentences: 1953\n",
      "Maximum sentence length: 364\n"
     ]
    }
   ],
   "source": [
    "print('train data')\n",
    "sentence_feat(train2_x)\n",
    "print('test data')\n",
    "sentence_feat(test2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_hist(train2_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences are longer in this new data set. In the histogram I can see that the average length of sentences is near 100 words per sentence. I will use 100 as the max sentence length for the model input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN2=100\n",
    "\n",
    "#fit tokenizer\n",
    "tokenizer2 = Tokenizer (num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer2.fit_on_texts(train2_x)\n",
    "word_index = tokenizer2.word_index\n",
    "\n",
    "#tokenize & pad train data\n",
    "train2_x_idx = tokenizer2.texts_to_sequences(train2_x)\n",
    "train2_x_idx = pad_sequences(train2_x_idx, maxlen=MAX_LEN2, padding='post')\n",
    "\n",
    "#tokenize & pad test data\n",
    "test2_x_idx = tokenizer.texts_to_sequences(test2_x)\n",
    "test2_x_idx = pad_sequences(test2_x_idx, maxlen=MAX_LEN2, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Origin': 0,\n",
       " 'Award': 1,\n",
       " 'Director': 2,\n",
       " 'Actor': 3,\n",
       " 'Character_Name': 4,\n",
       " 'Opinion': 5,\n",
       " 'Plot': 6,\n",
       " 'Soundtrack': 7,\n",
       " 'Quote': 8,\n",
       " 'Genre': 9,\n",
       " 'Relationship': 10,\n",
       " 'Year': 11,\n",
       " 'O': 12}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_dict, dictTot2, tags2 = tag_dict(train2_y)\n",
    "y2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_y_idx = tag_transform(y2_dict,train2_y,MAX_LEN2)\n",
    "test2_y_idx = tag_transform(y2_dict,test2_y,MAX_LEN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_y_idx[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words2 = Input(shape = (MAX_LEN2,))\n",
    "model2 = Embedding(input_dim = MAX_WORDS, output_dim = DIM, input_length = MAX_LEN2)(input_words2)\n",
    "model2 = Dropout(0.2)(model2)\n",
    "model2 = Bidirectional(LSTM(units = 128,return_sequences = True, recurrent_dropout = 0.1))(model2)\n",
    "out2 = TimeDistributed(Dense(dictTot2, activation = 'softmax'))(model2)\n",
    "model2 = Model(inputs=input_words2, outputs=out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 100, 256)          234496    \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 100, 13)           3341      \n",
      "=================================================================\n",
      "Total params: 1,237,837\n",
      "Trainable params: 1,237,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7816, 100)\n",
      "(7816, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "train2_y_idx=np.array(train2_y_idx)\n",
    "test2_y_idx=np.array(test2_y_idx)\n",
    "\n",
    "print(train2_x_idx.shape)\n",
    "print(train2_y_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 128s 1s/step - loss: 0.4977 - accuracy: 0.8793 - val_loss: 0.3272 - val_accuracy: 0.9115\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 131s 1s/step - loss: 0.2491 - accuracy: 0.9359 - val_loss: 0.2334 - val_accuracy: 0.9290\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 128s 1s/step - loss: 0.1744 - accuracy: 0.9482 - val_loss: 0.1751 - val_accuracy: 0.9484\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 122s 1s/step - loss: 0.1282 - accuracy: 0.9632 - val_loss: 0.1362 - val_accuracy: 0.9592\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 137s 1s/step - loss: 0.0986 - accuracy: 0.9715 - val_loss: 0.1142 - val_accuracy: 0.9650\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 120s 1s/step - loss: 0.0815 - accuracy: 0.9758 - val_loss: 0.1021 - val_accuracy: 0.9693\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 115s 1s/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0951 - val_accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 132s 1s/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 0.0938 - val_accuracy: 0.9724\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 130s 1s/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0927 - val_accuracy: 0.9721\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 134s 1s/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.0897 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x47ffd580>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train2_x_idx, train2_y_idx, batch_size = 64, verbose = 1, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 7s 111ms/step - loss: 0.5024 - accuracy: 0.8970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5023682713508606, 0.8970404267311096]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test2_x_idx, test2_y_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Improvements\n",
    "The model reaches 98.45% accuracy in the training data and 89.7% in the test data. This means that the model has a good performance, yet it's slightly overfitting the data, there is almost a 10% decrease in accuracy between the training and testing data. This means there's an opportunity to improve the regularization of the model in order for it to generalize better to unseen data. The potential improvements described in the first section can be applied to this model, in particular it would be useful to try different dropout values or layers, and try applying L2 regularization to the weights of the neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
